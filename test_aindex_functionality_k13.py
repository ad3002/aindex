import sys
import os
import logging
import numpy as np
import time
import subprocess

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ø—É—Ç–µ–π - –¥–æ–±–∞–≤–ª—è–µ–º –∫–æ—Ä–Ω–µ–≤—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –ø—Ä–æ–µ–∫—Ç–∞ –≤ Python path
PATH_TO_AINDEX_FOLDER = '..'
sys.path.insert(0, PATH_TO_AINDEX_FOLDER)

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# –ò–º–ø–æ—Ä—Ç –º–æ–¥—É–ª—è aindex - –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä—è–º–æ–π –∏–º–ø–æ—Ä—Ç C++ –º–æ–¥—É–ª—è –¥–ª—è 13-–º–µ—Ä–æ–≤
try:
    import aindex.core.aindex_cpp as aindex_cpp
    print("‚úì –ú–æ–¥—É–ª—å aindex_cpp —É—Å–ø–µ—à–Ω–æ –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω")
    
    # –¢–∞–∫–∂–µ –ø–æ–ø—Ä–æ–±—É–µ–º –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å Python wrapper
    try:
        from aindex.core.aindex import AIndex
        print("‚úì –ú–æ–¥—É–ª—å AIndex —Ç–∞–∫–∂–µ —É—Å–ø–µ—à–Ω–æ –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω")
        HAS_PYTHON_WRAPPER = True
    except ImportError as e:
        print(f"‚ö†Ô∏è Python wrapper –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω: {e}")
        HAS_PYTHON_WRAPPER = False
        AIndex = None
        
except ImportError as e:
    print(f"‚úó –û—à–∏–±–∫–∞ –∏–º–ø–æ—Ä—Ç–∞ aindex_cpp: {e}")
    print("–ü—Ä–æ–≤–µ—Ä—å—Ç–µ, —á—Ç–æ –ø–∞–∫–µ—Ç aindex —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –∏ —Å–æ–±—Ä–∞–Ω –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ")
    print("–í—ã–ø–æ–ª–Ω–∏—Ç–µ –≤ —Ç–µ—Ä–º–∏–Ω–∞–ª–µ:")
    print(f"  cd {PATH_TO_AINDEX_FOLDER}")
    print("  make pybind11")
    aindex_cpp = None
    AIndex = None
    HAS_PYTHON_WRAPPER = False

print("–†–∞–±–æ—á–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è:", os.getcwd())
print("Python –≤–µ—Ä—Å–∏—è:", sys.version)
print("–ü—É—Ç—å –∫ aindex:", PATH_TO_AINDEX_FOLDER)

assert aindex_cpp is not None, "–ú–æ–¥—É–ª—å aindex_cpp –Ω–µ –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω, —Ç–µ—Å—Ç—ã –Ω–µ –º–æ–≥—É—Ç –±—ã—Ç—å –≤—ã–ø–æ–ª–Ω–µ–Ω—ã"

# –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ —Ñ–∞–π–ª–æ–≤ –ø–µ—Ä–µ–¥ –∑–∞–≥—Ä—É–∑–∫–æ–π
prefix = os.path.join(PATH_TO_AINDEX_FOLDER, "temp/all_13mers")
required_files = [
    f"{prefix}.pf",
    f"{prefix}.index.bin", 
    f"{prefix}.kmers.bin"
]

# –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ —Ñ–∞–π–ª–∞ —Å —Ä–∏–¥–∞–º–∏ (–ø—É—Ç—å –±–µ–∑ —É—á–µ—Ç–∞ —Ä–∞–∑–º–µ—Ä–∞ k-–º–µ—Ä–æ–≤)
base_prefix = os.path.join(PATH_TO_AINDEX_FOLDER, "temp/reads")
reads_file = f"{base_prefix}.reads"
reads_index_file = f"{base_prefix}.ridx"  # –ü—Ä–∞–≤–∏–ª—å–Ω—ã–π –ø—É—Ç—å –∫ –∏–Ω–¥–µ–∫—Å—É —Ä–∏–¥–æ–≤
kmers_file = f"{prefix}.kmers"
has_reads = os.path.exists(reads_file) and os.path.exists(reads_index_file)

# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –ø–æ–¥—Å—á–µ—Ç–∞ —Å—Ç—Ä–æ–∫ –≤ —Ñ–∞–π–ª–µ
def count_lines(file_path):
    try:
        result = subprocess.run(["wc", "-l", file_path], capture_output=True, text=True)
        if result.returncode == 0:
            return int(result.stdout.split()[0])
        return None
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–¥—Å—á–µ—Ç–µ —Å—Ç—Ä–æ–∫ –≤ {file_path}: {e}")
        return None

def parse_kmers_analysis_file(file_path):
    """
    –ü–∞—Ä—Å–∏—Ç —Ñ–∞–π–ª kmers_analysis.trues –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ª–æ–≤–∞—Ä—å –∫–º–µ—Ä -> —á–∞—Å—Ç–æ—Ç–∞
    
    –§–æ—Ä–º–∞—Ç —Ñ–∞–π–ª–∞:
    kmer    frequency   [read_id,position,direction] [read_id,position,direction] ...
    """
    kmer_tf = {}
    
    if not os.path.exists(file_path):
        print(f"–§–∞–π–ª {file_path} –Ω–µ –Ω–∞–π–¥–µ–Ω, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –ø—Ä–æ–≤–µ—Ä–∫—É k-–º–µ—Ä–æ–≤")
        return kmer_tf
        
    try:
        with open(file_path, 'r') as f:
            for line in f:
                parts = line.strip().split('\t')
                if len(parts) >= 2:
                    kmer = parts[0]
                    frequency = int(parts[1])
                    kmer_tf[kmer] = frequency
        print(f"–ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(kmer_tf)} –∫–º–µ—Ä–æ–≤ –∏–∑ —Ñ–∞–π–ª–∞ {file_path}")
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ —Ñ–∞–π–ª–∞ {file_path}: {e}")
        
    return kmer_tf

# –ü–æ–ª—É—á–∞–µ–º –æ–∂–∏–¥–∞–µ–º–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–∏–¥–æ–≤ –∏ k-–º–µ—Ä–æ–≤
expected_reads_count = count_lines(reads_file) if os.path.exists(reads_file) else None
expected_kmers_count = count_lines(kmers_file) if os.path.exists(kmers_file) else None

print("–ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è —Ñ–∞–π–ª–æ–≤:")
all_files_exist = True
for file_path in required_files:
    exists = os.path.exists(file_path)
    print(f"  {file_path}: {'‚úì' if exists else '‚úó'}")
    if not exists:
        all_files_exist = False

print(f"  {reads_file}: {'‚úì' if os.path.exists(reads_file) else '‚úó'}")
print(f"  {reads_index_file}: {'‚úì' if os.path.exists(reads_index_file) else '‚úó'}")
print(f"  {kmers_file}: {'‚úì' if os.path.exists(kmers_file) else '‚úó'}")

print("\n–û–∂–∏–¥–∞–µ–º—ã–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞:")
if expected_reads_count:
    print(f"  –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–∏–¥–æ–≤ (wc -l {reads_file}): {expected_reads_count:,}")
if expected_kmers_count:
    print(f"  –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ k-–º–µ—Ä–æ–≤ (wc -l {kmers_file}): {expected_kmers_count:,}")

if not all_files_exist:
    print("\n‚ö†Ô∏è –ù–µ –≤—Å–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ —Ñ–∞–π–ª—ã –Ω–∞–π–¥–µ–Ω—ã. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ, —á—Ç–æ –∏–Ω–¥–µ–∫—Å –±—ã–ª —Å–æ–∑–¥–∞–Ω –ø—Ä–∞–≤–∏–ª—å–Ω–æ.")
    print(f"–û–∂–∏–¥–∞–µ–º—ã–µ —Ñ–∞–π–ª—ã –¥–æ–ª–∂–Ω—ã –Ω–∞—Ö–æ–¥–∏—Ç—å—Å—è –≤ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏: {os.path.dirname(prefix)}")
else:
    print("\n‚úì –í—Å–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ —Ñ–∞–π–ª—ã –Ω–∞–π–¥–µ–Ω—ã, –Ω–∞—á–∏–Ω–∞–µ–º –∑–∞–≥—Ä—É–∑–∫—É...")

# –ó–∞–≥—Ä—É–∂–∞–µ–º –∏–Ω–¥–µ–∫—Å —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ aindex_cpp –¥–æ—Å—Ç—É–ø–µ–Ω
if aindex_cpp is not None:
    try:
        start_time = time.time()
        print(f"–ó–∞–≥—Ä—É–∂–∞–µ–º 13-–º–µ—Ä–Ω—ã–π –∏–Ω–¥–µ–∫—Å –∏–∑ –ø—Ä–µ—Ñ–∏–∫—Å–∞: {prefix}")
        
        # –°–æ–∑–¥–∞–µ–º —ç–∫–∑–µ–º–ø–ª—è—Ä AindexWrapper –∏ –∑–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ
        index = aindex_cpp.AindexWrapper()
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º 13-–º–µ—Ä–Ω—ã–π –∏–Ω–¥–µ–∫—Å
        index.load_from_prefix_13mer(prefix)
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º —Ä–∏–¥—ã –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–Ω—ã
        if has_reads:
            print("–ó–∞–≥—Ä—É–∂–∞–µ–º —Ä–∏–¥—ã –≤ 13-–º–µ—Ä–Ω—ã–π –∏–Ω–¥–µ–∫—Å...")
            index.load_reads(reads_file)
            print(f"‚úì –†–∏–¥—ã –∑–∞–≥—Ä—É–∂–µ–Ω—ã: {index.n_reads:,} —Ä–∏–¥–æ–≤")
        else:
            print("‚ö†Ô∏è –§–∞–π–ª—ã —Ä–∏–¥–æ–≤ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã, –∑–∞–≥—Ä—É–∂–∞–µ–º —Ç–æ–ª—å–∫–æ TF –¥–∞–Ω–Ω—ã–µ")
        
        load_time = time.time() - start_time
        print(f"‚úì 13-–º–µ—Ä–Ω—ã–π –∏–Ω–¥–µ–∫—Å —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω –∑–∞ {load_time:.2f} —Å–µ–∫—É–Ω–¥")
        
        # –ë–∞–∑–æ–≤–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ 13-–º–µ—Ä–Ω–æ–º –∏–Ω–¥–µ–∫—Å–µ
        stats = index.get_13mer_statistics()
        print(f"–í—Å–µ–≥–æ 13-–º–µ—Ä–æ–≤: {stats['total_kmers']:,}")
        print(f"13-–º–µ—Ä—ã —Å –Ω–µ–Ω—É–ª–µ–≤—ã–º TF: {stats['non_zero_kmers']:,}")
        print(f"–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è —á–∞—Å—Ç–æ—Ç–∞: {stats['max_frequency']:,}")
        print(f"–û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ TF: {stats['total_count']:,}")
        print(f"–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–∏–¥–æ–≤: {index.n_reads:,}")
        print(f"–†–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞ —Ä–∏–¥–æ–≤: {index.reads_size:,} –±–∞–π—Ç")
        
        print(f"–ò–Ω–¥–µ–∫—Å –∑–∞–≥—Ä—É–∂–µ–Ω –¥–ª—è 13-–º–µ—Ä–æ–≤: True")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —Ä–∏–¥—ã –±—ã–ª–∏ –∑–∞–≥—Ä—É–∂–µ–Ω—ã
        if index.n_reads > 0:
            print(f"‚úì –†–∏–¥—ã —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω—ã ({index.n_reads:,} —Ä–∏–¥–æ–≤)")
            
            # –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –¥–æ—Å—Ç—É–ø–∞ –∫ —Ä–∏–¥–∞–º
            try:
                # –ü–æ–ª—É—á–∞–µ–º –ø–µ—Ä–≤—ã–π —Ä–∏–¥ –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏
                first_read = index.get_read_by_rid(0)
                if first_read:
                    print(f"–ü–µ—Ä–≤—ã–π —Ä–∏–¥ (–ø–µ—Ä–≤—ã–µ 50 —Å–∏–º–≤–æ–ª–æ–≤): {first_read[:50]}...")
            except Exception as e:
                print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –¥–æ—Å—Ç—É–ø–µ –∫ —Ä–∏–¥–∞–º: {e}")
        else:
            print("‚ö†Ô∏è –†–∏–¥—ã –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã –∏–ª–∏ –∏—Ö –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–∞–≤–Ω–æ 0")
        
        # –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –æ–∂–∏–¥–∞–µ–º–æ–≥–æ –∏ —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–æ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ (—É–±–∏—Ä–∞–µ–º, —Ç–∞–∫ –∫–∞–∫ –∏—Å–ø–æ–ª—å–∑—É–µ–º C++ API)
            
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —Ñ–∞–π–ª—É tf –¥–ª—è 13-–º–µ—Ä–æ–≤
        print("\n=== –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Ñ–∞–π–ª–∞ tf –¥–ª—è 13-–º–µ—Ä–æ–≤ ===")
        try:
            # –ü–æ–ª—É—á–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É —á–µ—Ä–µ–∑ –Ω–æ–≤—ã–π API
            stats = index.get_13mer_statistics()
            total_kmers = stats['total_kmers']
            non_zero_count = stats['non_zero_kmers']
            max_tf = stats['max_frequency']
            total_count = stats['total_count']
            avg_tf = total_count / non_zero_count if non_zero_count > 0 else 0
            
            print(f"–í—Å–µ–≥–æ 13-–º–µ—Ä–æ–≤: {total_kmers:,}")
            print(f"13-–º–µ—Ä–æ–≤ —Å –Ω–µ–Ω—É–ª–µ–≤—ã–º TF: {non_zero_count:,} ({non_zero_count*100/total_kmers:.2f}%)")
            print(f"–ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π TF: {max_tf:,}")
            print(f"–û–±—â–∏–π —Å—á–µ—Ç TF: {total_count:,}")
            print(f"–°—Ä–µ–¥–Ω–∏–π TF (–¥–ª—è –Ω–µ–Ω—É–ª–µ–≤—ã—Ö): {avg_tf:.2f}")
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ tf: {e}")
            
        # –£–±–∏—Ä–∞–µ–º –ø—Ä–æ–≤–µ—Ä–∫—É —Ä–∏–¥–æ–≤, —Ç–∞–∫ –∫–∞–∫ –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ–ª—å–∫–æ TF API –¥–ª—è 13-–º–µ—Ä–æ–≤
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è k-–º–µ—Ä–æ–≤ –∏ –∏—Ö —á–∞—Å—Ç–æ—Ç —Å –æ–∂–∏–¥–∞–µ–º—ã–º–∏ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏
        kmers_analysis_file = os.path.join(PATH_TO_AINDEX_FOLDER, "./temp/all_13mers.true.kmers")
        if os.path.exists(kmers_analysis_file):
            print("\n=== –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è 13-–º–µ—Ä–æ–≤ –æ–∂–∏–¥–∞–µ–º—ã–º –∑–Ω–∞—á–µ–Ω–∏—è–º ===")
            expected_kmers = parse_kmers_analysis_file(kmers_analysis_file)
            
            if expected_kmers:
                print(f"–ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(expected_kmers)} –æ–∂–∏–¥–∞–µ–º—ã—Ö 13-–º–µ—Ä–æ–≤ –∏–∑ {kmers_analysis_file}")
                
                # –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–µ—Ä–≤—ã—Ö –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö k-–º–µ—Ä–æ–≤ –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏
                sample_size = min(10, len(expected_kmers))
                sample_kmers = list(expected_kmers.keys())[:sample_size]
                
                print(f"\n–ü—Ä–æ–≤–µ—Ä–∫–∞ {sample_size} —Å–ª—É—á–∞–π–Ω—ã—Ö 13-–º–µ—Ä–æ–≤:")
                print("Kmer\t\t\t–û–∂–∏–¥–∞–ª–æ—Å—å\t–ü—Ä—è–º–æ–π\t–û–±—Ä–∞—Ç–Ω—ã–π\t–ò—Ç–æ–≥–æ\t–°—Ç–∞—Ç—É—Å")
                print("-" * 80)
                
                all_matched = True
                mismatches = 0
                
                for kmer in sample_kmers:
                    expected_tf = expected_kmers[kmer]
                    
                    # –ò—Å–ø–æ–ª—å–∑—É–µ–º –Ω–æ–≤—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è TF –≤ –æ–±–µ–∏—Ö –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—è—Ö
                    forward_tf, reverse_tf = index.get_tf_both_directions_13mer(kmer)
                    total_tf = index.get_total_tf_value_13mer(kmer)
                    
                    matches = expected_tf == total_tf
                    all_matched = all_matched and matches
                    if not matches:
                        mismatches += 1
                        
                    status = "‚úì" if matches else "‚úó"
                    print(f"{status} {kmer}\t{expected_tf}\t\t{forward_tf}\t{reverse_tf}\t{total_tf}\t{status}")
                
                # –ü—Ä–æ–≤–µ—Ä–∫–∞ –≤—Å–µ—Ö k-–º–µ—Ä–æ–≤
                print("\n–ü—Ä–æ–≤–µ—Ä–∫–∞ –≤—Å–µ—Ö 13-–º–µ—Ä–æ–≤:")
                total_mismatches = 0
                zero_tf_count = 0
                
                for kmer, expected_tf in expected_kmers.items():
                    total_tf = index.get_total_tf_value_13mer(kmer)
                    
                    if total_tf == 0:
                        zero_tf_count += 1
                    
                    if expected_tf != total_tf:
                        total_mismatches += 1
                        
                # –í—ã–≤–æ–¥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
                match_percentage = 100 * (len(expected_kmers) - total_mismatches) / len(expected_kmers)
                print(f"–°–æ–≤–ø–∞–ª–æ: {match_percentage:.2f}% 13-–º–µ—Ä–æ–≤")
                print(f"–ù–µ—Å–æ–≤–ø–∞–¥–µ–Ω–∏–π: {total_mismatches:,} –∏–∑ {len(expected_kmers):,} 13-–º–µ—Ä–æ–≤")
                print(f"13-–º–µ—Ä—ã —Å –Ω—É–ª–µ–≤–æ–π —á–∞—Å—Ç–æ—Ç–æ–π: {zero_tf_count:,}")
                
                if total_mismatches > 0:
                    print("\n‚ö†Ô∏è –û–±–Ω–∞—Ä—É–∂–µ–Ω—ã –Ω–µ—Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è –º–µ–∂–¥—É –æ–∂–∏–¥–∞–µ–º—ã–º–∏ –∏ —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–∏–º–∏ —á–∞—Å—Ç–æ—Ç–∞–º–∏ 13-–º–µ—Ä–æ–≤")
                else:
                    print("\n‚úì –í—Å–µ —á–∞—Å—Ç–æ—Ç—ã 13-–º–µ—Ä–æ–≤ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—Ç –æ–∂–∏–¥–∞–µ–º—ã–º –∑–Ω–∞—á–µ–Ω–∏—è–º")
            else:
                print("–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –æ–∂–∏–¥–∞–µ–º—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è 13-–º–µ—Ä–æ–≤ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏")
        else:
            print(f"\n‚ö†Ô∏è –§–∞–π–ª {kmers_analysis_file} –Ω–µ –Ω–∞–π–¥–µ–Ω, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –ø—Ä–æ–≤–µ—Ä–∫—É 13-–º–µ—Ä–æ–≤")
            print("  –î–ª—è —Å–æ–∑–¥–∞–Ω–∏—è —Ñ–∞–π–ª–∞ –≤—ã–ø–æ–ª–Ω–∏—Ç–µ:\n  python tests/analyze_kmers.py --input-file temp/reads.reads -o kmers_analysis.trues")
    except Exception as e:
        print(f"‚úó –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –∏–Ω–¥–µ–∫—Å–∞: {e}")
        import traceback
        traceback.print_exc()
        index = None
else:
    print("‚ö†Ô∏è aindex_cpp –Ω–µ –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –∑–∞–≥—Ä—É–∑–∫—É –∏–Ω–¥–µ–∫—Å–∞")
    index = None

# –ü–æ–ª—É—á–∞–µ–º –ø–æ–¥—Ä–æ–±–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ–± –∏–Ω–¥–µ–∫—Å–µ
if index is None:
    print("‚ö†Ô∏è –ò–Ω–¥–µ–∫—Å –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ")
else:
    print("=== –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ 13-–º–µ—Ä–Ω–æ–º –∏–Ω–¥–µ–∫—Å–µ ===")
    try:
        stats = index.get_13mer_statistics()
        print(f"–í—Å–µ–≥–æ 13-–º–µ—Ä–æ–≤: {stats['total_kmers']:,}")
        print(f"13-–º–µ—Ä—ã —Å –Ω–µ–Ω—É–ª–µ–≤—ã–º TF: {stats['non_zero_kmers']:,}")
        print(f"–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è —á–∞—Å—Ç–æ—Ç–∞: {stats['max_frequency']:,}")
        print(f"–û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ TF: {stats['total_count']:,}")
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏: {e}")

    print("\n=== –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ ===")
    print(f"–†–µ–∂–∏–º 13-–º–µ—Ä–æ–≤: –∞–∫—Ç–∏–≤–µ–Ω")

    # –¢–µ—Å—Ç–∏—Ä—É–µ–º –¥–æ—Å—Ç—É–ø –∫ TF –¥–ª—è –æ–¥–Ω–æ–≥–æ 13-–º–µ—Ä–∞
    test_kmer = "AAAAACCCCCGGG"  # 13-–º–µ—Ä –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
    print(f"\n–¢–µ—Å—Ç –¥–æ—Å—Ç—É–ø–∞ –∫ TF:")
    print(f"  13-–º–µ—Ä: '{test_kmer}'")
    try:
        forward_tf, reverse_tf = index.get_tf_both_directions_13mer(test_kmer)
        total_tf = index.get_total_tf_value_13–º–µ—Ä(test_kmer)
        rc_kmer = index.get_reverse_complement_13mer(test_kmer)
        
        print(f"  Forward TF: {forward_tf}")
        print(f"  Reverse TF: {reverse_tf} (RC: {rc_kmer})")
        print(f"  Total TF: {total_tf}")
    except Exception as e:
        print(f"  –û—à–∏–±–∫–∞: {e}")

# –¢–µ—Å—Ç–∏—Ä—É–µ–º –ø–æ–ª—É—á–µ–Ω–∏–µ term frequency –¥–ª—è 13-–º–µ—Ä–æ–≤
if index is None:
    print("‚ö†Ô∏è –ò–Ω–¥–µ–∫—Å –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ TF")
else:
    print("=== –¢–µ—Å—Ç –ø–æ–ª—É—á–µ–Ω–∏—è TF –¥–ª—è 13-–º–µ—Ä–æ–≤ ===")

    # –°–æ–∑–¥–∞–µ–º –Ω–µ—Å–∫–æ–ª—å–∫–æ —Ç–µ—Å—Ç–æ–≤—ã—Ö 13-–º–µ—Ä–æ–≤
    test_kmers = [
        "AAAAAAAAAAAAA",   # —Ç–æ–ª—å–∫–æ A
        "TTTTTTTTTTTTT",   # —Ç–æ–ª—å–∫–æ T
        "GGGGGGGGGGGGG",   # —Ç–æ–ª—å–∫–æ G
        "CCCCCCCCCCCCC",   # —Ç–æ–ª—å–∫–æ C
        "ATCGATCGATCGA",   # —Å–ª—É—á–∞–π–Ω–∞—è –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å
        "AAAAAGAGTTAAT",   # –∏–∑–≤–µ—Å—Ç–Ω—ã–π k-–º–µ—Ä –∏–∑ –Ω–∞—à–∏—Ö —Ç–µ—Å—Ç–æ–≤
        "AGTAGTAGTAGTA"    # –µ—â–µ –æ–¥–∏–Ω –∏–∑–≤–µ—Å—Ç–Ω—ã–π k-–º–µ—Ä
    ]

    print("–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –æ—Ç–¥–µ–ª—å–Ω—ã—Ö 13-–º–µ—Ä–æ–≤:")
    print("Kmer\t\t\tForward\tReverse\tTotal\tRC")
    print("-" * 80)
    
    for kmer in test_kmers:
        try:
            forward_tf, reverse_tf = index.get_tf_both_directions_13mer(kmer)
            total_tf = index.get_total_tf_value_13mer(kmer)
            rc_kmer = index.get_reverse_complement_13mer(kmer)
            print(f"{kmer}\t{forward_tf}\t{reverse_tf}\t{total_tf}\t{rc_kmer}")
        except Exception as e:
            print(f"{kmer}\tError: {e}")

    print("\n=== –¢–µ—Å—Ç batch –ø–æ–ª—É—á–µ–Ω–∏—è TF –¥–ª—è 13-–º–µ—Ä–æ–≤ ===")

    # –¢–µ—Å—Ç–∏—Ä—É–µ–º batch –æ–±—Ä–∞–±–æ—Ç–∫—É
    batch_kmers = test_kmers[:5]  # –±–µ—Ä–µ–º –ø–µ—Ä–≤—ã–µ 5
    try:
        start_time = time.time()
        
        # Batch –ø–æ–ª—É—á–µ–Ω–∏–µ TF –≤ –æ–±–µ–∏—Ö –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—è—Ö
        batch_results = index.get_tf_both_directions_13mer_batch(batch_kmers)
        
        # Batch –ø–æ–ª—É—á–µ–Ω–∏–µ –æ–±—â–µ–≥–æ TF
        total_tfs = index.get_total_tf_values_13mer(batch_kmers)
        
        batch_time = time.time() - start_time
        
        print(f"Batch –æ–±—Ä–∞–±–æ—Ç–∫–∞ {len(batch_kmers)} 13-–º–µ—Ä–æ–≤ –∑–∞–Ω—è–ª–∞ {batch_time:.4f} —Å–µ–∫—É–Ω–¥")
        print("–†–µ–∑—É–ª—å—Ç–∞—Ç—ã:")
        print("Kmer\t\t\tForward\tReverse\tTotal")
        print("-" * 60)
        
        for i, kmer in enumerate(batch_kmers):
            forward_tf, reverse_tf = batch_results[i]
            total_tf = total_tfs[i]
            print(f"{kmer}\t{forward_tf}\t{reverse_tf}\t{total_tf}")
            
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ batch –æ–±—Ä–∞–±–æ—Ç–∫–∏: {e}")

    print("\n=== –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –¥–ª—è 13-–º–µ—Ä–æ–≤ ===")

    # –°—Ä–∞–≤–Ω–∏–≤–∞–µ–º –æ–¥–∏–Ω–æ—á–Ω—ã–µ –≤—ã–∑–æ–≤—ã vs batch
    n_test = 100
    random_kmers = []
    for i in range(n_test):
        kmer = ''.join(np.random.choice(['A', 'T', 'G', 'C'], 13))
        random_kmers.append(kmer)

    # –û–¥–∏–Ω–æ—á–Ω—ã–µ –≤—ã–∑–æ–≤—ã
    start_time = time.time()
    single_results = []
    for kmer in random_kmers:
        try:
            total_tf = index.get_total_tf_value_13mer(kmer)
            single_results.append(total_tf)
        except:
            single_results.append(0)
    single_time = time.time() - start_time

    # Batch –≤—ã–∑–æ–≤
    start_time = time.time()
    try:
        batch_results = index.get_total_tf_values_13mer(random_kmers)
    except:
        batch_results = [0] * len(random_kmers)
    batch_time = time.time() - start_time

    print(f"–û–¥–∏–Ω–æ—á–Ω—ã–µ –≤—ã–∑–æ–≤—ã ({n_test} 13-–º–µ—Ä–æ–≤): {single_time:.4f} —Å–µ–∫")
    print(f"Batch –≤—ã–∑–æ–≤ ({n_test} 13-–º–µ—Ä–æ–≤): {batch_time:.4f} —Å–µ–∫")
    print(f"–£—Å–∫–æ—Ä–µ–Ω–∏–µ: {single_time/batch_time:.1f}x")

# –î–ª—è 13-–º–µ—Ä–Ω–æ–≥–æ API –ø–æ–∑–∏—Ü–∏–∏ –∏ —Ä–∏–¥—ã –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã, –∑–∞–≤–µ—Ä—à–∞–µ–º –æ—Å–Ω–æ–≤–Ω–æ–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ
print("\n=== –¢–µ—Å—Ç –∞–Ω–∞–ª–∏–∑ —Å–ª—É—á–∞–π–Ω—ã—Ö 13-–º–µ—Ä–æ–≤ ===")

if index is None:
    print("‚ö†Ô∏è –ò–Ω–¥–µ–∫—Å –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –∞–Ω–∞–ª–∏–∑")
else:
    # –ü—Ä–æ–≤–µ–¥–µ–º –∞–Ω–∞–ª–∏–∑ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è TF –¥–ª—è —Å–ª—É—á–∞–π–Ω—ã—Ö 13-–º–µ—Ä–æ–≤
    n_random = 1000
    print(f"–ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º {n_random} —Å–ª—É—á–∞–π–Ω—ã—Ö 13-–º–µ—Ä–æ–≤ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è TF...")
    
    random_kmers = []
    for i in range(n_random):
        kmer = ''.join(np.random.choice(['A', 'T', 'G', 'C'], 13))
        random_kmers.append(kmer)
    
    try:
        # –ü–æ–ª—É—á–∞–µ–º TF –¥–ª—è –≤—Å–µ—Ö —Å–ª—É—á–∞–π–Ω—ã—Ö k-–º–µ—Ä–æ–≤ batch'–µ–º
        total_tfs = index.get_total_tf_values_13mer(random_kmers)
        
        # –ê–Ω–∞–ª–∏–∑ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è
        non_zero_count = sum(1 for tf in total_tfs if tf > 0)
        max_tf = max(total_tfs) if total_tfs else 0
        avg_tf = sum(total_tfs) / len(total_tfs) if total_tfs else 0
        avg_non_zero_tf = sum(total_tfs) / non_zero_count if non_zero_count > 0 else 0
        
        print(f"–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–∞ {n_random} —Å–ª—É—á–∞–π–Ω—ã—Ö 13-–º–µ—Ä–æ–≤:")
        print(f"  13-–º–µ—Ä—ã —Å –Ω–µ–Ω—É–ª–µ–≤—ã–º TF: {non_zero_count} ({non_zero_count/n_random*100:.1f}%)")
        print(f"  –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π TF: {max_tf}")
        print(f"  –°—Ä–µ–¥–Ω–∏–π TF (–≤—Å–µ): {avg_tf:.2f}")
        print(f"  –°—Ä–µ–¥–Ω–∏–π TF (–Ω–µ–Ω—É–ª–µ–≤—ã–µ): {avg_non_zero_tf:.2f}")
        
        # –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ –¥–∏–∞–ø–∞–∑–æ–Ω–∞–º TF
        tf_ranges = {
            "0": 0,
            "1": 0,
            "2-5": 0,
            "6-10": 0,
            "11-50": 0,
            ">50": 0
        }
        
        for tf in total_tfs:
            if tf == 0:
                tf_ranges["0"] += 1
            elif tf == 1:
                tf_ranges["1"] += 1
            elif 2 <= tf <= 5:
                tf_ranges["2-5"] += 1
            elif 6 <= tf <= 10:
                tf_ranges["6-10"] += 1
            elif 11 <= tf <= 50:
                tf_ranges["11-50"] += 1
            else:
                tf_ranges[">50"] += 1
        
        print(f"\n–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ –¥–∏–∞–ø–∞–∑–æ–Ω–∞–º TF:")
        for range_name, count in tf_ranges.items():
            percentage = count / n_random * 100
            print(f"  {range_name}: {count} ({percentage:.1f}%)")
            
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ —Å–ª—É—á–∞–π–Ω—ã—Ö 13-–º–µ—Ä–æ–≤: {e}")

    # –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ —Å –±–æ–ª—å—à–∏–º–∏ –æ–±—ä–µ–º–∞–º–∏ –¥–∞–Ω–Ω—ã—Ö
    print(f"\n=== –¢–µ—Å—Ç –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –¥–ª—è –±–æ–ª—å—à–∏—Ö –æ–±—ä–µ–º–æ–≤ ===")
    
    large_n = 10000
    print(f"–¢–µ—Å—Ç–∏—Ä—É–µ–º –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –Ω–∞ {large_n} 13-–º–µ—Ä–∞—Ö...")
    
    large_random_kmers = []
    for i in range(large_n):
        kmer = ''.join(np.random.choice(['A', 'T', 'G', 'C'], 13))
        large_random_kmers.append(kmer)
    
    try:
        start_time = time.time()
        large_total_tfs = index.get_total_tf_values_13mer(large_random_kmers)
        large_batch_time = time.time() - start_time
        
        print(f"Batch –æ–±—Ä–∞–±–æ—Ç–∫–∞ {large_n} 13-–º–µ—Ä–æ–≤: {large_batch_time:.4f} —Å–µ–∫")
        print(f"–°–∫–æ—Ä–æ—Å—Ç—å: {large_n/large_batch_time:.0f} 13-–º–µ—Ä–æ–≤/—Å–µ–∫")
        
        # –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å –æ–¥–∏–Ω–æ—á–Ω—ã–º–∏ –≤—ã–∑–æ–≤–∞–º–∏ (–Ω–∞ –º–µ–Ω—å—à–µ–º –æ–±—ä–µ–º–µ)
        test_subset = large_random_kmers[:1000]
        
        start_time = time.time()
        for kmer in test_subset:
            index.get_total_tf_value_13mer(kmer)
        single_time = time.time() - start_time
        
        start_time = time.time()
        index.get_total_tf_values_13mer(test_subset)
        batch_subset_time = time.time() - start_time
        
        print(f"\n–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –Ω–∞ {len(test_subset)} 13-–º–µ—Ä–∞—Ö:")
        print(f"  –û–¥–∏–Ω–æ—á–Ω—ã–µ –≤—ã–∑–æ–≤—ã: {single_time:.4f} —Å–µ–∫ ({len(test_subset)/single_time:.0f} 13-–º–µ—Ä–æ–≤/—Å–µ–∫)")
        print(f"  Batch –≤—ã–∑–æ–≤: {batch_subset_time:.4f} —Å–µ–∫ ({len(test_subset)/batch_subset_time:.0f} 13-–º–µ—Ä–æ–≤/—Å–µ–∫)")
        print(f"  –£—Å–∫–æ—Ä–µ–Ω–∏–µ: {single_time/batch_subset_time:.1f}x")
        
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏: {e}")

    # –¢–µ—Å—Ç –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –¥–ª—è 1 –º–∏–ª–ª–∏–æ–Ω–∞ –∑–∞–ø—Ä–æ—Å–æ–≤
    print(f"\n=== –°–¢–†–ï–°–°-–¢–ï–°–¢: 1 –ú–ò–õ–õ–ò–û–ù –ó–ê–ü–†–û–°–û–í ===")
    
    million_n = 1000000
    print(f"–ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º {million_n:,} —Å–ª—É—á–∞–π–Ω—ã—Ö 13-–º–µ—Ä–æ–≤ –¥–ª—è —Å—Ç—Ä–µ—Å—Å-—Ç–µ—Å—Ç–∞...")
    
    # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö –ø–æ —á–∞—Å—Ç—è–º –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ –ø–∞–º—è—Ç–∏
    batch_size = 100000
    total_time = 0.0
    total_processed = 0
    
    print(f"–û–±—Ä–∞–±–æ—Ç–∫–∞ –ø–æ –±–∞—Ç—á–∞–º —Ä–∞–∑–º–µ—Ä–æ–º {batch_size:,}...")
    
    try:
        for batch_num in range(million_n // batch_size):
            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –±–∞—Ç—á
            batch_kmers = []
            for i in range(batch_size):
                kmer = ''.join(np.random.choice(['A', 'T', 'G', 'C'], 13))
                batch_kmers.append(kmer)
            
            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –±–∞—Ç—á
            start_time = time.time()
            batch_results = index.get_total_tf_values_13mer(batch_kmers)
            batch_time = time.time() - start_time
            
            total_time += batch_time
            total_processed += len(batch_kmers)
            
            # –ü—Ä–æ–≥—Ä–µ—Å—Å
            progress = (batch_num + 1) * batch_size
            print(f"  –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {progress:,}/{million_n:,} ({progress/million_n*100:.1f}%) "
                  f"- –í—Ä–µ–º—è –±–∞—Ç—á–∞: {batch_time:.3f}—Å, –°–∫–æ—Ä–æ—Å—Ç—å: {len(batch_kmers)/batch_time:.0f} 13-–º–µ—Ä–æ–≤/—Å–µ–∫")
        
        # –§–∏–Ω–∞–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        avg_speed = total_processed / total_time
        print(f"\nüöÄ –†–ï–ó–£–õ–¨–¢–ê–¢–´ –°–¢–†–ï–°–°-–¢–ï–°–¢–ê:")
        print(f"  –í—Å–µ–≥–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {total_processed:,} 13-–º–µ—Ä–æ–≤")
        print(f"  –û–±—â–µ–µ –≤—Ä–µ–º—è: {total_time:.3f} —Å–µ–∫—É–Ω–¥")
        print(f"  –°—Ä–µ–¥–Ω—è—è —Å–∫–æ—Ä–æ—Å—Ç—å: {avg_speed:.0f} 13-–º–µ—Ä–æ–≤/—Å–µ–∫")
        print(f"  –ü—Ä–æ–ø—É—Å–∫–Ω–∞—è —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç—å: {avg_speed/1000:.0f}K 13-–º–µ—Ä–æ–≤/—Å–µ–∫")
        print(f"  –í—Ä–µ–º—è –Ω–∞ –æ–¥–∏–Ω 13-–º–µ—Ä: {total_time/total_processed*1000000:.2f} –º–∏–∫—Ä–æ—Å–µ–∫—É–Ω–¥")
        
        # –ê–Ω–∞–ª–∏–∑ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö TF
        if 'batch_results' in locals():
            sample_non_zero = sum(1 for tf in batch_results if tf > 0)
            sample_max = max(batch_results) if batch_results else 0
            print(f"\nüìä –ê–Ω–∞–ª–∏–∑ –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ –±–∞—Ç—á–∞:")
            print(f"  13-–º–µ—Ä—ã —Å –Ω–µ–Ω—É–ª–µ–≤—ã–º TF: {sample_non_zero}/{len(batch_results)} ({sample_non_zero/len(batch_results)*100:.2f}%)")
            print(f"  –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π TF –≤ –±–∞—Ç—á–µ: {sample_max}")
        
        # –û—Ü–µ–Ω–∫–∞ –ø–∞–º—è—Ç–∏
        memory_per_kmer = 13  # –±–∞–π—Ç –Ω–∞ —Å—Ç—Ä–æ–∫—É k-–º–µ—Ä–∞
        memory_per_tf = 8     # –±–∞–π—Ç –Ω–∞ uint64_t —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        estimated_memory = batch_size * (memory_per_kmer + memory_per_tf) / 1024 / 1024
        print(f"\nüíæ –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø–∞–º—è—Ç–∏:")
        print(f"  –†–∞–∑–º–µ—Ä –±–∞—Ç—á–∞: {batch_size:,} 13-–º–µ—Ä–æ–≤")
        print(f"  –û—Ü–µ–Ω–æ—á–Ω–∞—è –ø–∞–º—è—Ç—å –Ω–∞ –±–∞—Ç—á: {estimated_memory:.1f} MB")
        print(f"  –û–±—â–∞—è —ç–∫–æ–Ω–æ–º–∏—è –ø–∞–º—è—Ç–∏: {(million_n * (memory_per_kmer + memory_per_tf) / 1024 / 1024) - estimated_memory:.0f} MB")
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ —Å—Ç—Ä–µ—Å—Å-—Ç–µ—Å—Ç–∞: {e}")
        import traceback
        traceback.print_exc()

    # –ë–µ–Ω—á–º–∞—Ä–∫ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è —Ä–∞–∑–Ω—ã—Ö —Ñ—É–Ω–∫—Ü–∏–π
    print(f"\n=== –ë–ï–ù–ß–ú–ê–†–ö –°–†–ê–í–ù–ï–ù–ò–Ø –§–£–ù–ö–¶–ò–ô ===")
    
    benchmark_n = 50000
    benchmark_kmers = []
    for i in range(benchmark_n):
        kmer = ''.join(np.random.choice(['A', 'T', 'G', 'C'], 13))
        benchmark_kmers.append(kmer)
    
    print(f"–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ —Ä–∞–∑–Ω—ã—Ö —Ñ—É–Ω–∫—Ü–∏–π –Ω–∞ {benchmark_n:,} 13-–º–µ—Ä–∞—Ö:")
    
    try:
        # 1. get_total_tf_values_13mer (batch)
        start_time = time.time()
        total_tfs = index.get_total_tf_values_13mer(benchmark_kmers)
        total_batch_time = time.time() - start_time
        
        # 2. get_tf_both_directions_13mer_batch
        start_time = time.time()
        both_directions = index.get_tf_both_directions_13mer_batch(benchmark_kmers)
        both_batch_time = time.time() - start_time
        
        # 3. get_tf_values_13mer (—Ç–æ–ª—å–∫–æ forward)
        start_time = time.time()
        forward_only = index.get_tf_values_13mer(benchmark_kmers)
        forward_batch_time = time.time() - start_time
        
        # 4. –û–¥–∏–Ω–æ—á–Ω—ã–µ –≤—ã–∑–æ–≤—ã (–Ω–∞ –ø–æ–¥–≤—ã–±–æ—Ä–∫–µ)
        subset = benchmark_kmers[:1000]
        start_time = time.time()
        for kmer in subset:
            index.get_total_tf_value_13mer(kmer)
        single_time = time.time() - start_time
        single_speed = len(subset) / single_time
        
        print(f"\nüìà –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –±–µ–Ω—á–º–∞—Ä–∫–∞:")
        print(f"  get_total_tf_values_13mer (batch):     {total_batch_time:.4f}—Å ({benchmark_n/total_batch_time:.0f} 13-–º–µ—Ä–æ–≤/—Å–µ–∫)")
        print(f"  get_tf_both_directions_13mer_batch:    {both_batch_time:.4f}—Å ({benchmark_n/both_batch_time:.0f} 13-–º–µ—Ä–æ–≤/—Å–µ–∫)")
        print(f"  get_tf_values_13mer (forward only):    {forward_batch_time:.4f}—Å ({benchmark_n/forward_batch_time:.0f} 13-–º–µ—Ä–æ–≤/—Å–µ–∫)")
        print(f"  –û–¥–∏–Ω–æ—á–Ω—ã–µ –≤—ã–∑–æ–≤—ã (—ç–∫—Å—Ç—Ä–∞–ø–æ–ª—è—Ü–∏—è):      {single_time:.4f}—Å ({single_speed:.0f} 13-–º–µ—Ä–æ–≤/—Å–µ–∫)")
        
        print(f"\nüèÜ –†–µ–π—Ç–∏–Ω–≥ –ø–æ —Å–∫–æ—Ä–æ—Å—Ç–∏:")
        speeds = [
            ("Forward only batch", benchmark_n/forward_batch_time),
            ("Total TF batch", benchmark_n/total_batch_time),
            ("Both directions batch", benchmark_n/both_batch_time),
            ("Single calls", single_speed)
        ]
        speeds.sort(key=lambda x: x[1], reverse=True)
        
        for i, (name, speed) in enumerate(speeds, 1):
            print(f"  {i}. {name}: {speed:.0f} 13-–º–µ—Ä–æ–≤/—Å–µ–∫")
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç–∏
        sample_idx = 0
        sample_kmer = benchmark_kmers[sample_idx]
        forward_tf, reverse_tf = both_directions[sample_idx]
        expected_total = forward_tf + reverse_tf
        actual_total = total_tfs[sample_idx]
        
        print(f"\n‚úÖ –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç–∏ (–ø—Ä–∏–º–µ—Ä: {sample_kmer}):")
        print(f"  Forward: {forward_tf}, Reverse: {reverse_tf}, –û–∂–∏–¥–∞–µ–º—ã–π total: {expected_total}")
        print(f"  –§–∞–∫—Ç–∏—á–µ—Å–∫–∏–π total: {actual_total}")
        print(f"  –ö–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç—å: {'‚úì' if expected_total == actual_total else '‚úó'}")
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –±–µ–Ω—á–º–∞—Ä–∫–∞: {e}")

    # –§–∏–Ω–∞–ª—å–Ω–∞—è —Å–≤–æ–¥–∫–∞ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è 13-–º–µ—Ä–Ω–æ–≥–æ –∏–Ω–¥–µ–∫—Å–∞
    print(f"\n" + "="*60)
    print(f"–°–í–û–î–ö–ê –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–Ø 13-–ú–ï–†–ù–û–ì–û –ò–ù–î–ï–ö–°–ê")
    print(f"="*60)
    prefix_display = f"{PATH_TO_AINDEX_FOLDER}/temp/all_13mers"
    print(f"–ü—Ä–µ—Ñ–∏–∫—Å: {prefix_display}")
    print(f"13-–º–µ—Ä–Ω—ã–π –∏–Ω–¥–µ–∫—Å –∑–∞–≥—Ä—É–∂–µ–Ω: ‚úì")
    
    try:
        stats = index.get_13mer_statistics()
        print(f"–í—Å–µ–≥–æ 13-–º–µ—Ä–æ–≤: {stats['total_kmers']:,}")
        print(f"13-–º–µ—Ä—ã —Å –Ω–µ–Ω—É–ª–µ–≤—ã–º TF: {stats['non_zero_kmers']:,}")
        print(f"–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è —á–∞—Å—Ç–æ—Ç–∞: {stats['max_frequency']:,}")
        print(f"–û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ TF: {stats['total_count']:,}")
        print(f"–°—Ä–µ–¥–Ω—è—è —á–∞—Å—Ç–æ—Ç–∞: {stats['total_count']/stats['non_zero_kmers']:.2f}")
    except:
        print("–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Ñ–∏–Ω–∞–ª—å–Ω—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É")

    print(f"\n‚úì –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ 13-–º–µ—Ä–Ω–æ–≥–æ –∏–Ω–¥–µ–∫—Å–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–æ —É—Å–ø–µ—à–Ω–æ!")

# –¢–µ—Å—Ç–∏—Ä—É–µ–º –∞–Ω–∞–ª–∏–∑ –ø–æ–∫—Ä—ã—Ç–∏—è –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ 13-–º–µ—Ä–∞–º–∏
if index is None:
    print("‚ö†Ô∏è –ò–Ω–¥–µ–∫—Å –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–æ–∫—Ä—ã—Ç–∏—è –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏")
else:
    print("=== –¢–µ—Å—Ç –∞–Ω–∞–ª–∏–∑–∞ –ø–æ–∫—Ä—ã—Ç–∏—è –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ 13-–º–µ—Ä–∞–º–∏ ===")

    test_sequences = []

    # –ü–æ–ª—É—á–∞–µ–º —Ä–µ–∞–ª—å–Ω—ã–µ —Ä–∏–¥—ã –Ω–∞–ø—Ä—è–º—É—é –∏–∑ 13-–º–µ—Ä–Ω–æ–≥–æ –∏–Ω–¥–µ–∫—Å–∞
    if index.n_reads > 0:
        print("–ü–æ–ª—É—á–∞–µ–º —Ä–µ–∞–ª—å–Ω—ã–µ —Ä–∏–¥—ã –∏–∑ 13-–º–µ—Ä–Ω–æ–≥–æ –∏–Ω–¥–µ–∫—Å–∞...")
        for rid in range(min(5, index.n_reads)):
            try:
                real_read = index.get_read_by_rid(rid)
                if real_read and len(real_read) >= 50:
                    # –ï—Å–ª–∏ —Ä–∏–¥ —Å–æ–¥–µ—Ä–∂–∏—Ç —Å—É–±—Ä–∏–¥—ã, –±–µ—Ä–µ–º –ø–µ—Ä–≤—ã–π —Å—É–±—Ä–∏–¥
                    if '~' in real_read:
                        seq = real_read.split('~')[0]
                    else:
                        seq = real_read
                    
                    # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª–∏–Ω—É –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏
                    if len(seq) > 100:
                        seq = seq[:100]
                    
                    if len(seq) >= 13:  # –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞ –¥–ª—è 13-–º–µ—Ä–æ–≤
                        test_sequences.append(seq)
                        print(f"  –î–æ–±–∞–≤–ª–µ–Ω —Ä–∏–¥ {rid}: –¥–ª–∏–Ω–∞ {len(seq)}")
                        
            except Exception as e:
                print(f"  –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ —Ä–∏–¥–∞ {rid}: {e}")
                continue
                        
        print(f"‚úì –ü–æ–ª—É—á–µ–Ω–æ {len(test_sequences)} —Ä–µ–∞–ª—å–Ω—ã—Ö –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π")
    
    # –ï—Å–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Ä–µ–∞–ª—å–Ω—ã–µ —Ä–∏–¥—ã, —Å–æ–∑–¥–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–µ
    if len(test_sequences) == 0:
        print("–°–æ–∑–¥–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–µ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –∏–∑ –∏–∑–≤–µ—Å—Ç–Ω—ã—Ö 13-–º–µ—Ä–æ–≤...")
        # –í–æ–∑—å–º–µ–º –Ω–µ—Å–∫–æ–ª—å–∫–æ –∏–∑–≤–µ—Å—Ç–Ω—ã—Ö 13-–º–µ—Ä–æ–≤ –∏ –æ–±—ä–µ–¥–∏–Ω–∏–º –∏—Ö
        known_kmers = ["AAAAAGAGTTAAT", "AGTAGTAGTAGTA", "ATCGATCGATCGA"]
        synthetic_seq = "".join(known_kmers) + "AAAAAAAAAA"  # –î–æ–±–∞–≤–ª—è–µ–º –Ω–µ–º–Ω–æ–≥–æ –ø–µ—Ä–µ–∫—Ä—ã—Ç–∏—è
        test_sequences.append(synthetic_seq)
        
        # –î–æ–±–∞–≤–∏–º –µ—â–µ –Ω–µ—Å–∫–æ–ª—å–∫–æ —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏—Ö –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π
        test_sequences.extend([
            "AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA",  # –ü—Ä–æ—Å—Ç–∞—è –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å —Ç–æ–ª—å–∫–æ A
            "ATCGATCGATCGATCGATCGATCGATCGATCGATCGAT",  # –ü–æ–≤—Ç–æ—Ä—è—é—â–∏–π—Å—è –ø–∞—Ç—Ç–µ—Ä–Ω
            "AAAAACCCCCGGGGGTTTTTATCGATCGAAAAAAA",     # –°–º–µ—à–∞–Ω–Ω–∞—è –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å
        ])
        print(f"‚úì –°–æ–∑–¥–∞–Ω–æ {len(test_sequences)} —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏—Ö –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π")

    for i, seq in enumerate(test_sequences):
        print(f"\n--- –ü–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å {i+1} (–¥–ª–∏–Ω–∞: {len(seq)}) ---")
        print(f"Seq: {seq[:50]}{'...' if len(seq) > 50 else ''}")
        
        if len(seq) < 13:
            print("  –ü–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∞—è –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ 13-–º–µ—Ä–æ–≤")
            continue
            
        try:
            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –ø–æ–∫—Ä—ã—Ç–∏–µ –¥–ª—è 13-–º–µ—Ä–æ–≤
            coverage_positions = []
            total_tf_sum = 0
            max_tf = 0
            non_zero_positions = 0
            
            # –ò—Ç–µ—Ä–∏—Ä—É–µ–º—Å—è –ø–æ –≤—Å–µ–º –≤–æ–∑–º–æ–∂–Ω—ã–º 13-–º–µ—Ä–∞–º –≤ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
            for pos in range(len(seq) - 12):
                kmer = seq[pos:pos+13]
                if len(kmer) == 13:
                    tf = index.get_total_tf_value_13mer(kmer)
                    coverage_positions.append((pos, kmer, tf))
                    total_tf_sum += tf
                    max_tf = max(max_tf, tf)
                    if tf > 0:
                        non_zero_positions += 1
            
            total_positions = len(coverage_positions)
            avg_tf = total_tf_sum / total_positions if total_positions > 0 else 0
            
            print(f"  –í—Å–µ–≥–æ –ø–æ–∑–∏—Ü–∏–π –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞: {total_positions}")
            print(f"  –ü–æ–∑–∏—Ü–∏–π —Å –Ω–µ–Ω—É–ª–µ–≤—ã–º TF: {non_zero_positions} ({non_zero_positions/total_positions*100:.1f}%)")
            print(f"  –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π TF: {max_tf}")
            print(f"  –°—Ä–µ–¥–Ω–∏–π TF: {avg_tf:.2f}")
            
            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ –Ω–µ—Å–∫–æ–ª—å–∫–æ 13-–º–µ—Ä–æ–≤ —Å –∏—Ö TF
            print(f"  –ü–µ—Ä–≤—ã–µ 5 13-–º–µ—Ä–æ–≤:")
            for j in range(min(5, len(coverage_positions))):
                pos, kmer, tf = coverage_positions[j]
                print(f"    –ü–æ–∑ {pos}: {kmer} -> TF = {tf}")
                
            # –¢–µ—Å—Ç–∏—Ä—É–µ–º —Å —Ä–∞–∑–ª–∏—á–Ω—ã–º–∏ cutoff (—Å–∏–º—É–ª—è—Ü–∏—è)
            cutoffs = [0, 1, 5, 10] if max_tf > 0 else [0]
            for cutoff in cutoffs:
                filtered_positions = sum(1 for _, _, tf in coverage_positions if tf >= cutoff)
                print(f"  –° TF >= {cutoff}: {filtered_positions} –ø–æ–∑–∏—Ü–∏–π")
                
        except Exception as e:
            print(f"  –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –ø–æ–∫—Ä—ã—Ç–∏—è: {e}")

    # –¢–µ—Å—Ç–∏—Ä—É–µ–º –∏—Ç–µ—Ä–∞—Ü–∏—é –ø–æ 13-–º–µ—Ä–∞–º –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
    print(f"\n=== –¢–µ—Å—Ç –∏—Ç–µ—Ä–∞—Ü–∏–∏ –ø–æ 13-–º–µ—Ä–∞–º –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ ===")
    
    test_seq = test_sequences[0][:50] if len(test_sequences[0]) > 50 else test_sequences[0]
    print(f"–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å –¥–ª–∏–Ω–æ–π {len(test_seq)}")
    print(f"–ü–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å: {test_seq}")
    
    try:
        kmer_count = 0
        tf_sum = 0
        non_zero_kmers = 0
        
        for pos in range(len(test_seq) - 12):
            kmer = test_seq[pos:pos+13]
            if len(kmer) == 13:
                tf = index.get_total_tf_value_13mer(kmer)
                kmer_count += 1
                tf_sum += tf
                if tf > 0:
                    non_zero_kmers += 1
                
                # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 5 13-–º–µ—Ä–æ–≤ —Å –Ω–µ–Ω—É–ª–µ–≤—ã–º TF
                if tf > 0 and non_zero_kmers <= 5:
                    print(f"  13-–º–µ—Ä {kmer_count}: {kmer} -> TF = {tf}")
                    
        if kmer_count > 0:
            coverage_percent = (non_zero_kmers / kmer_count) * 100 if kmer_count > 0 else 0
            print(f"–í—Å–µ–≥–æ 13-–º–µ—Ä–æ–≤: {kmer_count}")
            print(f"13-–º–µ—Ä—ã —Å –Ω–µ–Ω—É–ª–µ–≤—ã–º TF: {non_zero_kmers} ({coverage_percent:.2f}%)")
            print(f"–°—Ä–µ–¥–Ω–∏–π TF: {tf_sum/kmer_count:.2f}")
            
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –∏—Ç–µ—Ä–∞—Ü–∏–∏ –ø–æ 13-–º–µ—Ä–∞–º: {e}")

# –°—Ç—Ä–µ—Å—Å-—Ç–µ—Å—Ç –∞–Ω–∞–ª–∏–∑–∞ –ø–æ–∫—Ä—ã—Ç–∏—è –¥–ª—è 13-–º–µ—Ä–æ–≤
if index is not None:
    print("\n" + "="*80)
    print("–°–¢–†–ï–°–°-–¢–ï–°–¢: –ê–ù–ê–õ–ò–ó –ü–û–ö–†–´–¢–ò–Ø –î–õ–Ø 10,000 –ü–û–°–õ–ï–î–û–í–ê–¢–ï–õ–¨–ù–û–°–¢–ï–ô (13-–ú–ï–†–´)")
    print("="*80)
    
    # –°–æ–±–∏—Ä–∞–µ–º —Ä–µ–∞–ª—å–Ω—ã–µ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –∏–∑ –∏–Ω–¥–µ–∫—Å–∞
    test_sequences_stress = []
    print("–°–æ–±–∏—Ä–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–µ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –∏–∑ 13-–º–µ—Ä–Ω–æ–≥–æ –∏–Ω–¥–µ–∫—Å–∞...")
    
    # –ü–æ–ª—É—á–∞–µ–º —Ä–µ–∞–ª—å–Ω—ã–µ —Ä–∏–¥—ã –Ω–∞–ø—Ä—è–º—É—é –∏–∑ 13-–º–µ—Ä–Ω–æ–≥–æ –∏–Ω–¥–µ–∫—Å–∞
    if index.n_reads > 0:
        print("–ó–∞–≥—Ä—É–∂–∞–µ–º —Ä–µ–∞–ª—å–Ω—ã–µ —Ä–∏–¥—ã –∏–∑ 13-–º–µ—Ä–Ω–æ–≥–æ –∏–Ω–¥–µ–∫—Å–∞...")
        
        # –í–æ–∑—å–º–µ–º –ø–µ—Ä–≤—ã–µ 10K —Ä–∏–¥–æ–≤ (–∏–ª–∏ —Å–∫–æ–ª—å–∫–æ –µ—Å—Ç—å)
        max_sequences = min(10000, index.n_reads)
        
        for rid in range(max_sequences):
            try:
                real_read = index.get_read_by_rid(rid)
                if real_read and len(real_read) >= 50:  # –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
                    # –ï—Å–ª–∏ —Ä–∏–¥ —Å–æ–¥–µ—Ä–∂–∏—Ç —Å—É–±—Ä–∏–¥—ã, –±–µ—Ä–µ–º –ø–µ—Ä–≤—ã–π —Å—É–±—Ä–∏–¥
                    if '~' in real_read:
                        seq = real_read.split('~')[0]
                    else:
                        seq = real_read
                    
                    # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª–∏–Ω—É –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ–≥–æ –≤—Ä–µ–º–µ–Ω–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è
                    if len(seq) > 200:
                        seq = seq[:200]
                    
                    if len(seq) >= 13:  # –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞ –¥–ª—è 13-–º–µ—Ä–æ–≤
                        test_sequences_stress.append(seq)
                        
                # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å –∫–∞–∂–¥—ã–µ 1000 –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π
                if (rid + 1) % 1000 == 0:
                    print(f"  –°–æ–±—Ä–∞–Ω–æ: {len(test_sequences_stress)} –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π –∏–∑ {rid + 1} —Ä–∏–¥–æ–≤")
                    
            except Exception as e:
                continue  # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –ø—Ä–æ–±–ª–µ–º–Ω—ã–µ —Ä–∏–¥—ã
        
        print(f"‚úì –°–æ–±—Ä–∞–Ω–æ {len(test_sequences_stress)} —Ä–µ–∞–ª—å–Ω—ã—Ö –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π –∏–∑ 13-–º–µ—Ä–Ω–æ–≥–æ –∏–Ω–¥–µ–∫—Å–∞")
    
    # –ï—Å–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Ä–µ–∞–ª—å–Ω—ã–µ —Ä–∏–¥—ã, –≥–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏–µ
    if len(test_sequences_stress) == 0:
        print("‚ö†Ô∏è –†–∏–¥—ã –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã –≤ 13-–º–µ—Ä–Ω—ã–π –∏–Ω–¥–µ–∫—Å")
        print("–ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏–µ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –¥–ª—è 13-–º–µ—Ä–æ–≤...")
        max_sequences = 10000
        
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Å–ª—É—á–∞–π–Ω—ã–µ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ —Ä–∞–∑–Ω–æ–π –¥–ª–∏–Ω—ã
        for i in range(max_sequences):
            # –°–ª—É—á–∞–π–Ω–∞—è –¥–ª–∏–Ω–∞ –æ—Ç 50 –¥–æ 150 –Ω—É–∫–ª–µ–æ—Ç–∏–¥–æ–≤
            seq_length = np.random.randint(50, 151)
            seq = ''.join(np.random.choice(['A', 'T', 'G', 'C'], seq_length))
            test_sequences_stress.append(seq)
            
            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å –∫–∞–∂–¥—ã–µ 1000 –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π
            if (i + 1) % 1000 == 0:
                print(f"  –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ: {i + 1:,} / {max_sequences:,} –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π")
        
        print(f"‚úì –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ {len(test_sequences_stress):,} —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏—Ö –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π")
    
    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π
    seq_lengths = [len(seq) for seq in test_sequences_stress]
    avg_length = sum(seq_lengths) / len(seq_lengths)
    min_length = min(seq_lengths)
    max_length = max(seq_lengths)
    
    print(f"–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π:")
    print(f"  –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ: {len(test_sequences_stress):,}")
    print(f"  –°—Ä–µ–¥–Ω—è—è –¥–ª–∏–Ω–∞: {avg_length:.1f} –Ω—Ç")
    print(f"  –î–∏–∞–ø–∞–∑–æ–Ω –¥–ª–∏–Ω: {min_length} - {max_length} –Ω—Ç")
    
    # –û—Ü–µ–Ω–æ—á–Ω—ã–π —Ä–∞—Å—á–µ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ 13-–º–µ—Ä–æ–≤
    total_kmers = sum(max(0, len(seq) - 12) for seq in test_sequences_stress)
    print(f"  –û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ 13-–º–µ—Ä–æ–≤ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞: {total_kmers:,}")
    
    print(f"\n--- –°—Ç—Ä–µ—Å—Å-—Ç–µ—Å—Ç –∞–Ω–∞–ª–∏–∑–∞ –ø–æ–∫—Ä—ã—Ç–∏—è –¥–ª—è 13-–º–µ—Ä–æ–≤ ---")
    
    # –ó–∞–º–µ—Ä—è–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø–∞–º—è—Ç–∏ –¥–æ —Ç–µ—Å—Ç–∞
    import psutil
    import os
    process = psutil.Process(os.getpid())
    memory_before = process.memory_info()
    
    print(f"–ü–∞–º—è—Ç—å –¥–æ —Ç–µ—Å—Ç–∞: RSS = {memory_before.rss / 1024 / 1024:.1f} –ú–ë")
    
    # –ó–∞–ø—É—Å–∫–∞–µ–º —Ç–µ—Å—Ç
    start_time = time.time()
    processed_sequences = 0
    total_positions_analyzed = 0
    total_nonzero_positions = 0
    total_tf_sum = 0
    max_tf_found = 0
    
    print("–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –ø–æ–∫—Ä—ã—Ç–∏–µ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π 13-–º–µ—Ä–∞–º–∏...")
    
    try:
        for i, seq in enumerate(test_sequences_stress):
            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –ø–æ–∫—Ä—ã—Ç–∏–µ –¥–ª—è –∫–∞–∂–¥–æ–π –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
            coverage = []
            
            # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ 13-–º–µ—Ä—ã –∏–∑ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
            kmers_in_seq = []
            for pos in range(len(seq) - 12):
                kmer = seq[pos:pos+13]
                if len(kmer) == 13:
                    kmers_in_seq.append(kmer)
            
            if len(kmers_in_seq) == 0:
                continue
                
            # –ü–æ–ª—É—á–∞–µ–º TF –¥–ª—è –≤—Å–µ—Ö 13-–º–µ—Ä–æ–≤ –≤ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ batch'–µ–º
            tf_values = index.get_total_tf_values_13mer(kmers_in_seq)
            
            # –°–æ–±–∏—Ä–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
            processed_sequences += 1
            total_positions_analyzed += len(tf_values)
            nonzero_positions = sum(1 for tf in tf_values if tf > 0)
            total_nonzero_positions += nonzero_positions
            tf_sum = sum(tf_values)
            total_tf_sum += tf_sum
            max_tf_in_seq = max(tf_values) if tf_values else 0
            max_tf_found = max(max_tf_found, max_tf_in_seq)
            
            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å –∫–∞–∂–¥—ã–µ 1000 –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π
            if processed_sequences % 1000 == 0:
                elapsed = time.time() - start_time
                sequences_per_sec = processed_sequences / elapsed if elapsed > 0 else 0
                positions_per_sec = total_positions_analyzed / elapsed if elapsed > 0 else 0
                
                print(f"  –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {processed_sequences:,} / {len(test_sequences_stress):,} " +
                      f"({sequences_per_sec:.1f} seq/—Å–µ–∫, {positions_per_sec:.0f} –ø–æ–∑–∏—Ü–∏–π/—Å–µ–∫)")
        
        end_time = time.time()
        elapsed_time = end_time - start_time
        
        # –ó–∞–º–µ—Ä—è–µ–º –ø–∞–º—è—Ç—å –ø–æ—Å–ª–µ —Ç–µ—Å—Ç–∞
        memory_after = process.memory_info()
        memory_increase = (memory_after.rss - memory_before.rss) / 1024 / 1024
        
        print(f"\n--- –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å—Ç—Ä–µ—Å—Å-—Ç–µ—Å—Ç–∞ –¥–ª—è 13-–º–µ—Ä–æ–≤ ---")
        print(f"‚úì –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π: {processed_sequences:,}")
        print(f"‚úì –û–±—â–µ–µ –≤—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è: {elapsed_time:.2f} —Å–µ–∫—É–Ω–¥")
        print(f"‚úì –ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å:")
        print(f"  - –ü–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π –≤ —Å–µ–∫—É–Ω–¥—É: {processed_sequences / elapsed_time:.1f}")
        print(f"  - 13-–º–µ—Ä –ø–æ–∑–∏—Ü–∏–π –≤ —Å–µ–∫—É–Ω–¥—É: {total_positions_analyzed / elapsed_time:.0f}")
        print(f"  - –í—Ä–µ–º—è –Ω–∞ –æ–¥–Ω—É –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å: {elapsed_time * 1000 / processed_sequences:.2f} –º—Å")
        
        print(f"\n‚úì –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ–∫—Ä—ã—Ç–∏—è –¥–ª—è 13-–º–µ—Ä–æ–≤:")
        print(f"  - –í—Å–µ–≥–æ –ø–æ–∑–∏—Ü–∏–π –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ: {total_positions_analyzed:,}")
        print(f"  - –ü–æ–∑–∏—Ü–∏–π —Å –Ω–µ–Ω—É–ª–µ–≤—ã–º TF: {total_nonzero_positions:,} ({total_nonzero_positions/total_positions_analyzed*100:.1f}%)")
        print(f"  - –°—Ä–µ–¥–Ω–∏–π TF –Ω–∞ –ø–æ–∑–∏—Ü–∏—é: {total_tf_sum/total_positions_analyzed:.2f}")
        print(f"  - –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π TF: {max_tf_found}")
        print(f"  - –û–±—â–∞—è —Å—É–º–º–∞ TF: {total_tf_sum:,}")
        
        print(f"\n‚úì –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø–∞–º—è—Ç–∏:")
        print(f"  - –ü–∞–º—è—Ç—å –ø–æ—Å–ª–µ —Ç–µ—Å—Ç–∞: RSS = {memory_after.rss / 1024 / 1024:.1f} –ú–ë")
        print(f"  - –ü—Ä–∏—Ä–æ—Å—Ç –ø–∞–º—è—Ç–∏: {memory_increase:+.1f} –ú–ë")
        
        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π —Ç–µ—Å—Ç: –Ω–µ—Å–∫–æ–ª—å–∫–æ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π —Å —Ä–∞–∑–Ω—ã–º–∏ –ø–æ–¥—Ö–æ–¥–∞–º–∏
        print(f"\n--- –¢–µ—Å—Ç —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –ø–æ–¥—Ö–æ–¥–æ–≤ –¥–ª—è 13-–º–µ—Ä–æ–≤ ---")
        test_sample = test_sequences_stress[:100]  # –í–æ–∑—å–º–µ–º 100 –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π
        
        # –ü–æ–¥—Ö–æ–¥ 1: Batch –æ–±—Ä–∞–±–æ—Ç–∫–∞ –≤—Å–µ—Ö 13-–º–µ—Ä–æ–≤ —Å—Ä–∞–∑—É
        start_batch_time = time.time()
        all_kmers = []
        for seq in test_sample:
            for pos in range(len(seq) - 12):
                kmer = seq[pos:pos+13]
                if len(kmer) == 13:
                    all_kmers.append(kmer)
        
        batch_results = index.get_total_tf_values_13mer(all_kmers)
        batch_time = time.time() - start_batch_time
        
        # –ü–æ–¥—Ö–æ–¥ 2: –ü–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –ø–æ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—è–º
        start_seq_time = time.time()
        total_positions_seq = 0
        for seq in test_sample:
            kmers_in_seq = []
            for pos in range(len(seq) - 12):
                kmer = seq[pos:pos+13]
                if len(kmer) == 13:
                    kmers_in_seq.append(kmer)
            
            if kmers_in_seq:
                seq_results = index.get_total_tf_values_13mer(kmers_in_seq)
                total_positions_seq += len(seq_results)
        
        seq_time = time.time() - start_seq_time
        
        print(f"  –ü–æ–¥—Ö–æ–¥ 1 (–≤—Å–µ 13-–º–µ—Ä—ã —Å—Ä–∞–∑—É): {batch_time:.3f} —Å–µ–∫, {len(all_kmers)} 13-–º–µ—Ä–æ–≤")
        print(f"  –ü–æ–¥—Ö–æ–¥ 2 (–ø–æ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—è–º): {seq_time:.3f} —Å–µ–∫, {total_positions_seq} –ø–æ–∑–∏—Ü–∏–π")
        print(f"  –†–∞–∑–Ω–∏—Ü–∞: {abs(batch_time - seq_time):.3f} —Å–µ–∫")
        
        print(f"\n" + "="*80)
        print(f"–°–¢–†–ï–°–°-–¢–ï–°–¢ –ü–û–ö–†–´–¢–ò–Ø –î–õ–Ø 13-–ú–ï–†–û–í –ó–ê–í–ï–†–®–ï–ù")
        print(f"="*80)
        print(f"‚úì –£—Å–ø–µ—à–Ω–æ –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ {processed_sequences:,} –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π")
        print(f"‚úì –ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å: {processed_sequences / elapsed_time:.1f} –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π/—Å–µ–∫")
        print(f"‚úì –û–±—â–µ–µ –≤—Ä–µ–º—è: {elapsed_time:.2f} —Å–µ–∫—É–Ω–¥")
        print(f"‚úì –ê–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ {total_positions_analyzed:,} –ø–æ–∑–∏—Ü–∏–π 13-–º–µ—Ä–æ–≤")
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ —Å—Ç—Ä–µ—Å—Å-—Ç–µ—Å—Ç–∞ –ø–æ–∫—Ä—ã—Ç–∏—è: {e}")
        import traceback
        traceback.print_exc()
else:
    print("\n‚ö†Ô∏è –ò–Ω–¥–µ–∫—Å –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º —Å—Ç—Ä–µ—Å—Å-—Ç–µ—Å—Ç –ø–æ–∫—Ä—ã—Ç–∏—è –¥–ª—è 13-–º–µ—Ä–æ–≤")
